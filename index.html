<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="aiping.liang s home">
<meta property="og:type" content="website">
<meta property="og:title" content="Aiping.LAP">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Aiping.LAP">
<meta property="og:description" content="aiping.liang s home">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Aiping.LAP">
<meta name="twitter:description" content="aiping.liang s home">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Aiping.LAP</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Aiping.LAP</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">认真工作，快乐生活</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/11/22/Apache-Eagle-基本介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/11/22/Apache-Eagle-基本介绍/" itemprop="url">Apache Eagle 基本介绍</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-11-21T14:23:35-08:00">
                2017-11-21
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/10/12/Ranger对HSFS实现控制管理的流程分析/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/10/12/Ranger对HSFS实现控制管理的流程分析/" itemprop="url">Ranger对HDFS实现管理和控制的流程分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-10-11T14:23:35-08:00">
                2017-10-11
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="一、Apache-Ranger简介"><a href="#一、Apache-Ranger简介" class="headerlink" title="一、Apache Ranger简介"></a>一、Apache Ranger简介</h1><p>​       Apache Ranger提供一个集中式安全管理框架, 并解决授权和审计。它可以对Hadoop生态的组件如HDFS、Yarn、Hive、Hbase等进行细粒度的数据访问控制。通过操作Ranger控制台,管理员可以轻松的通过配置策略来控制用户访问权限。在2017年2月左右，Apache 软件基金会<a href="https://blogs.apache.org/foundation/entry/the-apache-software-foundation-announces3" target="_blank" rel="external">宣布</a>，Apache Ranger 已经成功地从孵化毕业，成为基金会的一个新的顶级项目</p>
<h1 id="二、Instrumentation-简介"><a href="#二、Instrumentation-简介" class="headerlink" title="二、Instrumentation 简介"></a>二、Instrumentation 简介</h1><p>​      利用 Java 代码，即 java.lang.instrument 做动态 Instrumentation 是 Java SE 5 的新特性，它把 Java 的 instrument 功能从本地代码中解放出来，使之可以用 Java 代码的方式解决问题。使用 Instrumentation，开发者可以构建一个独立于应用程序的代理程序（Agent），用来监测和协助运行在 JVM 上的程序，甚至能够替换和修改某些类的定义。有了这样的功能，开发者就可以实现更为灵活的运行时虚拟机监控和 Java 类操作了，这样的特性实际上提供了一种虚拟机级别支持的 AOP 实现方式，使得开发者无需对 JDK 做任何升级和改动，就可以实现某些 AOP 的功能。</p>
<h1 id="三、Ranger利用Instrumentation实现对HDFS的权限控制和管理"><a href="#三、Ranger利用Instrumentation实现对HDFS的权限控制和管理" class="headerlink" title="三、Ranger利用Instrumentation实现对HDFS的权限控制和管理"></a>三、Ranger利用Instrumentation实现对HDFS的权限控制和管理</h1><h2 id="1、策略的编辑和管理"><a href="#1、策略的编辑和管理" class="headerlink" title="1、策略的编辑和管理"></a>1、策略的编辑和管理</h2><p>​       Ranger对于用户策略的控制是通过控制台完成的，首先是通过ServiceREST的updatePolicy方法，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@PUT</span></div><div class="line"><span class="meta">@Path</span>(<span class="string">"/services/&#123;id&#125;"</span>)</div><div class="line"><span class="meta">@Produces</span>(&#123; <span class="string">"application/json"</span>, <span class="string">"application/xml"</span> &#125;)</div><div class="line"><span class="meta">@PreAuthorize</span>(<span class="string">"@rangerPreAuthSecurityHandler.isAPIAccessible(\""</span> + RangerAPIList.UPDATE_SERVICE + <span class="string">"\")"</span>) <span class="comment">//这里会对界面的操作者鉴权，确定是否有相应的管理员权限编辑当前的策略</span></div><div class="line"><span class="function"><span class="keyword">public</span> RangerService <span class="title">updateService</span><span class="params">(RangerService service)</span> </span>&#123;</div><div class="line">     <span class="comment">//...省略上下文</span></div><div class="line">     </div><div class="line">      <span class="comment">//这里主要检查输入的参数中，是否缺少了必须要有的参数</span></div><div class="line">		RangerPolicyValidator validator = validatorFactory.getPolicyValidator(svcStore);</div><div class="line">		validator.validate(policy, Action.UPDATE, bizUtil.isAdmin());</div><div class="line"></div><div class="line">		ensureAdminAccess(policy.getService(), policy.getResources());</div><div class="line"></div><div class="line">		ret = svcStore.updatePolicy(policy);</div><div class="line">      <span class="comment">//...省略上下文</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>然后调用ServiceDBStore的updatePolicy的方法把更新的策略直接写入到数据库中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> RangerPolicy <span class="title">updatePolicy</span><span class="params">(RangerPolicy policy)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line">  <span class="comment">//...省略上下文</span></div><div class="line"></div><div class="line">   XXPolicy xxExisting = daoMgr.getXXPolicy().getById(policy.getId());</div><div class="line">   <span class="comment">//确定是一个存在的服务类型，比如HDFS</span></div><div class="line">   RangerPolicy existing = policyService.getPopulatedViewObject(xxExisting);</div><div class="line">   <span class="comment">//确定是已经创建的一个服务，例如Sandbox_hadoop</span></div><div class="line">   RangerService service = getServiceByName(policy.getService());</div><div class="line">   <span class="comment">//..这里省略了一些和上面类似的判断，都是在完成写入前不为空的一些逻辑检查</span></div><div class="line">   </div><div class="line">   <span class="comment">//这里是目前支持的四种类型的策略，多个策略组成了策略组，也就是一条policy</span></div><div class="line">   List&lt;RangerPolicyItem&gt; policyItems     = policy.getPolicyItems();</div><div class="line">   List&lt;RangerPolicyItem&gt; denyPolicyItems = policy.getDenyPolicyItems();</div><div class="line">   List&lt;RangerPolicyItem&gt; allowExceptions = policy.getAllowExceptions();</div><div class="line">   List&lt;RangerPolicyItem&gt; denyExceptions  = policy.getDenyExceptions();</div><div class="line">   <span class="comment">//..skip</span></div><div class="line">   <span class="comment">//写入相应的策略到数据库中</span></div><div class="line">   createNewPolicyItemsForPolicy(policy, newUpdPolicy, policyItems, xServiceDef, RangerPolicyItemEvaluator.POLICY_ITEM_TYPE_ALLOW);</div><div class="line"></div><div class="line">  <span class="comment">//很重要的一步，更新策略的版本号，方便后续根据版本号确定客户端执行最新的策略</span></div><div class="line">   handlePolicyUpdate(service, isTagVersionUpdateNeeded);</div><div class="line">   <span class="comment">//把上一步的策略存储起来，方便后续的回滚和查询</span></div><div class="line">   RangerPolicy updPolicy = policyService.getPopulatedViewObject(newUpdPolicy);</div><div class="line">   dataHistService.createObjectDataHistory(updPolicy, RangerDataHistService.ACTION_UPDATE);</div><div class="line">   <span class="comment">//所有的transaction Log (XXTrxLog)都是用于审计 </span></div><div class="line">   bizUtil.createTrxLog(trxLogList);</div><div class="line">   </div><div class="line">   <span class="keyword">return</span> updPolicy;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="2、触发策略的更新"><a href="#2、触发策略的更新" class="headerlink" title="2、触发策略的更新"></a>2、触发策略的更新</h2><p> Ranger服务端对于策略更新后，客户端获取更新后的策略的方式比较简单，就是通过一个异步的类PolicyRefresher来不断的检查策略的id是否发生了更新，然后就调用更新，默认更新的间隔是pollingIntervalMs   = 30 * 1000。更新主要调用的方法如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">loadPolicy</span><span class="params">()</span> </span>&#123;</div><div class="line"></div><div class="line">   RangerPerfTracer perf = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">//获取需要更新的策略列表</span></div><div class="line">      ServicePolicies svcPolicies = loadPolicyfromPolicyAdmin();</div><div class="line"></div><div class="line">      <span class="comment">//如果获取到的策略列表为空，则直接从上次的缓存中读取，否则把结果写入到缓存</span></div><div class="line">      <span class="keyword">if</span> (svcPolicies == <span class="keyword">null</span>) &#123;</div><div class="line">         <span class="keyword">if</span> (!policiesSetInPlugin) &#123;</div><div class="line">            svcPolicies = loadFromCache();</div><div class="line">         &#125;</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         saveToCache(svcPolicies);</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span> (svcPolicies != <span class="keyword">null</span>) &#123;</div><div class="line">        <span class="comment">//注意，这里的RangerHdfsPlugin是后续鉴权中使用的插件</span></div><div class="line">         plugIn.setPolicies(svcPolicies);</div><div class="line">         policiesSetInPlugin = <span class="keyword">true</span>;</div><div class="line">         <span class="comment">//这两部很重要，每次更新完之后，一定要设置上一次更新的时间和版本号</span></div><div class="line">         setLastActivationTimeInMillis(System.currentTimeMillis());</div><div class="line">         lastKnownVersion = svcPolicies.getPolicyVersion();</div><div class="line">      &#125; <span class="keyword">else</span> &#123;</div><div class="line">         <span class="keyword">if</span> (!policiesSetInPlugin &amp;&amp; !serviceDefSetInPlugin) &#123;</div><div class="line">            plugIn.setPolicies(<span class="keyword">null</span>);</div><div class="line">            serviceDefSetInPlugin = <span class="keyword">true</span>;</div><div class="line">         &#125;</div><div class="line">      &#125;</div><div class="line">   &#125; <span class="keyword">catch</span> (RangerServiceNotFoundException snfe) &#123;</div><div class="line">      <span class="comment">//一旦更新失败，则回滚所有的版本号到最原始的版本，然后下一次会下载所有的版本</span></div><div class="line">      <span class="keyword">if</span> (disableCacheIfServiceNotFound) &#123;</div><div class="line">         disableCache();</div><div class="line">         plugIn.setPolicies(<span class="keyword">null</span>);</div><div class="line">         setLastActivationTimeInMillis(System.currentTimeMillis());</div><div class="line">         lastKnownVersion = -<span class="number">1</span>;</div><div class="line">         serviceDefSetInPlugin = <span class="keyword">true</span>;</div><div class="line">      &#125;</div><div class="line">   &#125; <span class="keyword">catch</span> (Exception excp) &#123;</div><div class="line">      LOG.error(<span class="string">"Encountered unexpected exception, ignoring.."</span>, excp);</div><div class="line">   &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>获取需要更新的策略的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> ServicePolicies <span class="title">loadPolicyfromPolicyAdmin</span><span class="params">()</span> <span class="keyword">throws</span> RangerServiceNotFoundException </span>&#123;</div><div class="line">  <span class="comment">//...省略一些无关内容</span></div><div class="line"></div><div class="line">   ServicePolicies svcPolicies = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">   RangerPerfTracer perf = <span class="keyword">null</span>;</div><div class="line"></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">//根据上次更新完以后的版本号，以及上次更新的时间，来获取所有需要更新的内容</span></div><div class="line">      svcPolicies = rangerAdmin.getServicePoliciesIfUpdated(lastKnownVersion, lastActivationTimeInMillis);</div><div class="line"></div><div class="line">      <span class="keyword">boolean</span> isUpdated = svcPolicies != <span class="keyword">null</span>;</div><div class="line">     <span class="comment">//如果获取到的更新内容不为空，则把所有的更新内容</span></div><div class="line">      <span class="keyword">if</span>(isUpdated) &#123;</div><div class="line">         <span class="keyword">long</span> newVersion = svcPolicies.getPolicyVersion() == <span class="keyword">null</span> ? -<span class="number">1</span> : svcPolicies.getPolicyVersion().longValue();</div><div class="line"></div><div class="line">         <span class="keyword">if</span>(!StringUtils.equals(serviceName, svcPolicies.getServiceName())) &#123;</div><div class="line">            LOG.warn(<span class="string">"PolicyRefresher(serviceName="</span> + serviceName + <span class="string">"): ignoring unexpected serviceName '"</span> + svcPolicies.getServiceName() + <span class="string">"' in service-store"</span>);</div><div class="line"></div><div class="line">            svcPolicies.setServiceName(serviceName);</div><div class="line">         &#125;</div><div class="line">    <span class="keyword">return</span> svcPolicies;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="3、通过插件最终实现对hdfs的权限控制"><a href="#3、通过插件最终实现对hdfs的权限控制" class="headerlink" title="3、通过插件最终实现对hdfs的权限控制"></a>3、通过插件最终实现对hdfs的权限控制</h2><p>   在上文中，我们介绍了Instrumentation的技术，在ranger中，通过HadoopAuthClassTransformer类来实现注入，并且检查所有访问org/apache/hadoop/hdfs/server/namenode/FSPermissionChecker方法的请求。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="keyword">public</span> <span class="keyword">byte</span>[] transform(ClassLoader aClassLoader, String aClassName, Class&lt;?&gt; aClassBeingRedefined, ProtectionDomain aProtectionDomain, <span class="keyword">byte</span>[] aClassFileBuffer) <span class="keyword">throws</span> IllegalClassFormatException &#123;</div><div class="line">   <span class="keyword">byte</span>[] ret = aClassFileBuffer;</div><div class="line"></div><div class="line">   <span class="comment">//拦截Hadoop原始的文件权限鉴权类FSPermissionChecker</span></div><div class="line">   <span class="keyword">if</span> (aClassName.equals(<span class="string">"org/apache/hadoop/hdfs/server/namenode/FSPermissionChecker"</span>)) &#123;</div><div class="line">           <span class="keyword">byte</span>[] result = transformedClassByteCode;</div><div class="line">           <span class="keyword">if</span> (result == <span class="keyword">null</span>) &#123;</div><div class="line"></div><div class="line">         <span class="keyword">byte</span>[] injectedClassCode = injectFSPermissionCheckerHooks(aClassName);</div><div class="line"></div><div class="line">         <span class="keyword">if</span>(injectedClassCode != <span class="keyword">null</span>) &#123;</div><div class="line">                   <span class="comment">//通过HadoopAuthClassTransformer来实现控制</span></div><div class="line">                   <span class="keyword">synchronized</span> (HadoopAuthClassTransformer.class) &#123;</div><div class="line">                       result = transformedClassByteCode;</div><div class="line">                       <span class="keyword">if</span> (result == <span class="keyword">null</span>) &#123;</div><div class="line">                           transformedClassByteCode = result = injectedClassCode;</div><div class="line">                       &#125;</div><div class="line">                   &#125;</div><div class="line">               &#125;</div><div class="line">      &#125;</div><div class="line"></div><div class="line">      <span class="keyword">if</span>(result != <span class="keyword">null</span>) &#123;</div><div class="line">         ret = result;</div><div class="line">      &#125;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">   <span class="keyword">return</span> ret;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>   HDFS默认使用的权限检查策略为FSPermissionChecker，这部分的检查是在namenode中，当用户在获取要访问数据的元数据的时候，进行检查，在org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">checkPermission</span><span class="params">(INodesInPath inodesInPath, <span class="keyword">boolean</span> doCheckOwner,</span></span></div><div class="line">  //...skip</div><div class="line">  //获取acl的控制对象,这里通过调用了RangerHdfsAuthorizer来生成一个内部类RangerAccessControlEnforcer对象</div><div class="line">  AccessControlEnforcer enforcer =</div><div class="line">      getAttributesProvider().<span class="title">getExternalAccessControlEnforcer</span><span class="params">(<span class="keyword">this</span>)</span>;</div><div class="line">   <span class="comment">//权限检查,这里调用了RangerAccessControlEnforcer来进行实际的检查</span></div><div class="line">  enforcer.checkPermission(fsOwner, supergroup, callerUgi, inodeAttrs, inodes,</div><div class="line">      pathByNameArr, snapshotId, path, ancestorIndex, doCheckOwner,</div><div class="line">      ancestorAccess, parentAccess, access, subAccess, ignoreEmptyDir);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>在RangerHdfsAuthorizer中的内部类getExternalAccessControlEnforcer实现了INodeAttributeProvider的权限检查接口AccessControlEnforcer，替代了默认的FSPermissionChecker提供的checkPermission方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@Override</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkPermission</span><span class="params">(String fsOwner, String superGroup, UserGroupInformation ugi,</span></span></div><div class="line">                     INodeAttributes[] inodeAttrs, INode[] inodes, <span class="keyword">byte</span>[][] pathByNameArr,</div><div class="line">                     <span class="keyword">int</span> snapshotId, String path, <span class="keyword">int</span> ancestorIndex, <span class="keyword">boolean</span> doCheckOwner,</div><div class="line">                     FsAction ancestorAccess, FsAction parentAccess, FsAction access,</div><div class="line">                     FsAction subAccess, <span class="keyword">boolean</span> ignoreEmptyDir) <span class="keyword">throws</span> AccessControlException &#123;</div><div class="line">  <span class="comment">//...skip</span></div><div class="line"></div><div class="line">   <span class="keyword">try</span> &#123;</div><div class="line">      <span class="comment">//先确定RangerHdfsPlugin不为空</span></div><div class="line">      <span class="keyword">if</span>(plugin != <span class="keyword">null</span> &amp;&amp; !ArrayUtils.isEmpty(inodes)) &#123;</div><div class="line">         <span class="keyword">if</span>(ancestorIndex &gt;= inodes.length) &#123;</div><div class="line">            ancestorIndex = inodes.length - <span class="number">1</span>;</div><div class="line">         &#125;</div><div class="line"></div><div class="line">         <span class="comment">//轮训所有的要访问的节点</span></div><div class="line">         <span class="keyword">for</span>(; ancestorIndex &gt;= <span class="number">0</span> &amp;&amp; inodes[ancestorIndex] == <span class="keyword">null</span>; ancestorIndex--);</div><div class="line">        <span class="comment">//...skip</span></div><div class="line"></div><div class="line">         <span class="comment">// 跳过白名单用户和owner的检查</span></div><div class="line">         <span class="comment">// 判断是否有父路径的权限</span></div><div class="line">         <span class="comment">//检查当前节点的路径权限</span></div><div class="line">         <span class="comment">//检查访问的类型</span></div><div class="line">         <span class="comment">//...经过一系列检查后，如果不抛出异常，则认为当前用户可以访问指定的资源</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>参考文章：</p>
<p><a href="https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html" target="_blank" rel="external">https://www.ibm.com/developerworks/cn/java/j-lo-jse61/index.html</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/23/Hadoop开启LZO后的压测/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/23/Hadoop开启LZO后的压测/" itemprop="url">Hadoop开启LZO后的压测</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-22T19:54:05-08:00">
                2016-03-22
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="压测的方法"><a href="#压测的方法" class="headerlink" title="压测的方法"></a>压测的方法</h1><h2 id="通过Straming把压缩普通文件成为LZO的格式"><a href="#通过Straming把压缩普通文件成为LZO的格式" class="headerlink" title="通过Straming把压缩普通文件成为LZO的格式"></a>通过Straming把压缩普通文件成为LZO的格式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">hadoop jar /opt/hadoop/hadoop-2.6.0/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar`</div><div class="line">`-Dmapred.min.split.size=$[1024*1024*1024]`</div><div class="line">`-D mapred.output.compress=true`</div><div class="line">`-D mapred.output.compression.codec=com.hadoop.compression.lzo.LzopCodec`</div><div class="line">`-D mapred.job.name=lap_lzo_compress`</div><div class="line">`-D mapred.reduce.tasks=0`</div><div class="line">`-mapper /bin/cat`</div><div class="line">`-input /raw_data/kafka/sourcedata/input/2016-03-02`</div><div class="line">`-output /raw_data/kafka/sourcedata/input/2016-03-02_tmp</div></pre></td></tr></table></figure>
<p>当然也可以map的时候做一些处理，然后在输出的时候压缩</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">`hadoop jar /opt/hadoop/hadoop-2.6.0/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar -Dmapred.min.split.size=$[1024*1024*1024]`</div><div class="line">`-D mapreduce.output.fileoutputformat.compress=true`</div><div class="line">`-D mapreduce.output.fileoutputformat.compress.codec=com.hadoop.compression.lzo.LzopCodec`</div><div class="line">`-D mapred.job.name=lap_lzo_compress`</div><div class="line">`-D stream.non.zero.exit.is.failure=false`</div><div class="line">`-mapper /bin/cat`</div><div class="line">`-reducer /bin/cat`</div><div class="line">`-input /user/lap/SecurityAuth-hadoop.audit`</div><div class="line">`-output /user/lap/output4`</div></pre></td></tr></table></figure>
<h2 id="通过Streaming读取压缩文件"><a href="#通过Streaming读取压缩文件" class="headerlink" title="通过Streaming读取压缩文件"></a>通过Streaming读取压缩文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">hadoop jar /opt/hadoop/hadoop-2.6.0/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar -Dmapred.min.split.size=$[1024*1024*1024]`</div><div class="line"></div><div class="line">`-D mapred.job.name=lap_lzo_compress`</div><div class="line"></div><div class="line">`-D mapred.reduce.tasks=0`</div><div class="line"></div><div class="line">`-D stream.non.zero.exit.is.failure=false`</div><div class="line"></div><div class="line">`-inputformat com.hadoop.mapred.DeprecatedLzoTextInputFormat`</div><div class="line"></div><div class="line">`-mapper /bin/cat`</div><div class="line"></div><div class="line">`-input /user/lap/lzo_output/part-00000.lzo`</div><div class="line"></div><div class="line">`-output /user/lap/lzooutput/outtest2</div></pre></td></tr></table></figure>
<h2 id="MapReduce任务中，读取和输出压缩类型的文件"><a href="#MapReduce任务中，读取和输出压缩类型的文件" class="headerlink" title="MapReduce任务中，读取和输出压缩类型的文件"></a>MapReduce任务中，读取和输出压缩类型的文件</h2><p>首先，编译的时候需要获取到LZO的压缩的包。 在线上，这个包一般的存放路径为：    ${HADOOP_HOME}/share/hadoop/common/hadoop-lzo-0.4.20-SNAPSHOT.jar</p>
<p>写一个简单的java版的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">lzoMapperOutput</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span></span>&#123;</div><div class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</div><div class="line">        <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">            StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</div><div class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</div><div class="line">                word.set(itr.nextToken());</div><div class="line">                context.write(word, one);</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span> </span>&#123;</div><div class="line">        <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</div><div class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</div><div class="line">            <span class="keyword">int</span> sum = <span class="number">0</span>;</div><div class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</div><div class="line">                sum += val.get();</div><div class="line">            &#125;</div><div class="line">            result.set(sum);</div><div class="line">            context.write(key, result);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String [] args)</span> <span class="keyword">throws</span> Exception</span>&#123;</div><div class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">        Job job = Job.getInstance(conf);</div><div class="line">        job.setJarByClass(lzoMapperOutput.class);</div><div class="line">        job.setMapperClass(TokenizerMapper.class);</div><div class="line">        job.setCombinerClass(IntSumReducer.class);</div><div class="line">        job.setReducerClass(IntSumReducer.class);</div><div class="line">        job.setOutputKeyClass(Text.class);</div><div class="line">        job.setOutputValueClass(IntWritable.class);</div><div class="line"></div><div class="line">        <span class="comment">//需要修改的地方，这里是重点</span></div><div class="line">        <span class="comment">//读取lzo类型的压缩的时候，进行以下的设置，或者通过conf的变量进行设置，或者通过Job提供的方法进行设置</span></div><div class="line">        <span class="comment">//注意conf的方式设置的话，需要在Job.getInstance(conf)初始化Job这一步之前</span></div><div class="line">        <span class="comment">// conf.setClass(MRJobConfig.INPUT_FORMAT_CLASS_ATTR, com.hadoop.mapreduce.LzoTextInputFormat.class,InputFormat.class);</span></div><div class="line">        job.setInputFormatClass(com.hadoop.mapreduce.LzoTextInputFormat.class);</div><div class="line">        <span class="comment">//也可以设置单独的shuffle为LZO，但是线上默认开启的是snappy压缩，所以建议不要覆盖</span></div><div class="line"></div><div class="line">        <span class="comment">//设置输出类型为LZO</span></div><div class="line">        FileOutputFormat.setCompressOutput(job, <span class="keyword">true</span>);</div><div class="line">        FileOutputFormat.setOutputCompressorClass(job, com.hadoop.compression.lzo.LzopCodec.class);</div><div class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</div><div class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</div><div class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="Hive使用LZO的压缩"><a href="#Hive使用LZO的压缩" class="headerlink" title="Hive使用LZO的压缩"></a>Hive使用LZO的压缩</h2><p>Hive表使用LZO压缩的时候，需要在创建表的时候把压缩属性更改成lzo的格式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">CREATE` `TABLE` ``raw_kafka_input_dt3`(`</div><div class="line">`   ```customer` string,`</div><div class="line">`   ```uid` ``int``)`</div><div class="line">`ROW FORMAT DELIMITED`</div><div class="line">`    ``FIELDS TERMINATED ``BY` `&apos;\t&apos;`</div><div class="line">`STORED ``AS` `INPUTFORMAT`</div><div class="line">`    ``&apos;com.hadoop.mapred.DeprecatedLzoTextInputFormat&apos;`</div><div class="line">`OUTPUTFORMAT`</div><div class="line">`     ``&apos;org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat&apos;`</div></pre></td></tr></table></figure>
<p>注意，以上的inputformat在使用alter的时候会导致历史数据被删除，所以在更改属性之前，备份一下数据，也不建议使用这种方式申明。 仅仅把表的InputFormat修改为lzo的压缩还不够，因为压缩完后的文件，用传统的方式无法被切分，所以map就只能是一个，所以需要为压缩文件创建一个索引，这样才可以使用分布式的压缩，创建方法如下： hadoop jar ${HADOOP_HOME}/share/hadoop/common/hadoop-lzo-0.4.20-SNAPSHOT.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/库名/表名 创建完索引后，以上的任务就是分布式的了。</p>
<h2 id="HBase表使用LZO压缩"><a href="#HBase表使用LZO压缩" class="headerlink" title="HBase表使用LZO压缩"></a>HBase表使用LZO压缩</h2><p>修改表开启LZO压缩： alter ‘表名’,{NAME=&gt;’列簇名’,COMPRESSION=&gt;’LZO’} </p>
<h1 id="测试总结"><a href="#测试总结" class="headerlink" title="测试总结"></a>测试总结</h1><p>其实一直有种误解,就是以为lzo本身是支持分布式的,也就是支持压缩后的数据可以分片.我们提供给它分片的逻辑,由lzo本身控制.但看了Hadoop lzo源码才发现,lzo只是个压缩和解压缩的工具,如何分片,是由Hadoop lzo(Javad代码里)控制.具体的分片算法写得也很简单,就是在内存中开一块大大的缓存,默认是256K,缓存可以在通过io.compression.codec.lzo.buffersize参数指定.数据读入缓存(实际上要更小一些),如果缓存满了,则交给lzo压缩,获取压缩后的数据,同时在lzo文件中写入压缩前后的大小以及压缩后的数据.所以这里,一个分片,其实就是&lt;=缓存大小.也就是我们常常使用的lzo索引机制。</p>
<h1 id="遇到的问题以及解决办法"><a href="#遇到的问题以及解决办法" class="headerlink" title="遇到的问题以及解决办法"></a>遇到的问题以及解决办法</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">`Error: java.io.IOException: No LZO codec found, cannot run.`</div><div class="line"></div><div class="line">`at com.hadoop.mapred.DeprecatedLzoLineRecordReader.(DeprecatedLzoLineRecordReader.java:53)`</div><div class="line"></div><div class="line">`at com.hadoop.mapred.DeprecatedLzoTextInputFormat.getRecordReader(DeprecatedLzoTextInputFormat.java:156)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.mapred.MapTask$TrackedRecordReader.(MapTask.java:169)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.mapred.MapTask.runOldMapper(MapTask.java:429)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.mapred.MapTask.run(MapTask.java:343)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)`</div><div class="line"></div><div class="line">`at java.security.AccessController.doPrivileged(Native Method)`</div><div class="line"></div><div class="line">`at javax.security.auth.Subject.doAs(Subject.java:415)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)`</div><div class="line"></div><div class="line">`at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)</div></pre></td></tr></table></figure>
<p>这个是因为在查找split的压缩类型的时候，返回空了，根本原因是没有在core-site.xml中正确配置集群中所有支持的压缩类型，key 是io.compression.codecs value是org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.SnappyCodec</p>
<h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>1、如果集群中没有在默认配置core-site.xml中加载lzo的压缩的话，使用hadoop fs -text 无法读取lzo、snappy压缩后的文件 </p>
<p>2、快速的检测一个文件是否是lzo，且集群支持lzo的方法 hadoop org.apache.hadoop.io.compress.CompressionCodecFactory $filepath </p>
<p>3、对于所有的流式的任务，InputFormat的类型都应该是 com.hadoop.mapred.DeprecatedLzoTextInputFormat 对于普通的MR任务，InputFormat的类型是: com.hadoop.mapreduce.LzoTextInputFormat.class</p>
<h1 id="测试效果"><a href="#测试效果" class="headerlink" title="测试效果"></a>测试效果</h1><p>1、存储对比 </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">359809200161 /raw_data/kafka/sourcedata/input/2016-03-02 </div><div class="line"></div><div class="line">133941395118 /raw_data/kafka/sourcedata/input/2016-03-02_lzo_tmp </div><div class="line"></div><div class="line">142546974490 /raw_data/kafka/sourcedata/input/2016-03-02_snappy_tmp </div><div class="line"></div><div class="line">54598916288 /raw_data/kafka/sourcedata/input/2016-03-02_tmp</div></pre></td></tr></table></figure>
<p>2、计算对比 </p>
<p>以线上的Input_Format为例，开启shuffle的snappy压缩后，效果明显：<br>从开启的压缩后的一段时间内，最多时候能到50%的性能优化， 从每天整体的性能看，大约能节约30%左右(以前每天总的执行时间(单位秒)6700W，到现在5000W左右)</p>
<h1 id="LZO加载"><a href="#LZO加载" class="headerlink" title="LZO加载"></a>LZO加载</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">`2016-03-17 14:53:16,192 DEBUG [main] com.hadoop.compression.lzo.GPLNativeCodeLoader: location: /native/Linux-amd64-64/lib`</div><div class="line">`2016-03-17 14:53:16,193 DEBUG [main] com.hadoop.compression.lzo.GPLNativeCodeLoader: temporary unpacked path: /opt/data7/yarn_dir/local/usercache/hadoop/appcache/application_1458035422051_0621/container_1458035422051_0621_01_000279/tmp/unpacked-7314810008241798412-libgplcompression.so`</div><div class="line">`2016-03-17 14:53:16,194 INFO [main] com.hadoop.compression.lzo.GPLNativeCodeLoader: Loaded native gpl library from the embedded binaries`</div><div class="line">`2016-03-17 14:53:16,197 INFO [main] com.hadoop.compression.lzo.LzoCodec: Successfully loaded &amp; initialized native-lzo library [hadoop-lzo rev d62701d4d05dfa6115bbaf8d9dff002df142e62d]</div></pre></td></tr></table></figure>
<p>`</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2016/03/11/长期更新一些HBase有用的工具和特性/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2016/03/11/长期更新一些HBase有用的工具和特性/" itemprop="url">长期更新一些HBase有用的工具和特性</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-03-10T21:15:52-08:00">
                2016-03-10
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="新的特性整理"><a href="#新的特性整理" class="headerlink" title="新的特性整理"></a>新的特性整理</h1><p>1、HBase存储图片，文档等字节流的内容</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-11339" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-11339</a> </p>
<p>2、compact的速度控制 </p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-8329" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-8329</a> </p>
<p>3、关于scan强制控制超时的一个问题，相当与给scan本身加了一个心跳</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-13090" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-13090</a></p>
<p>4、在执行HBase的BULK Load的时候，如果导入失败，但是如果写了WAL也认为是成功，这是个BUG</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15425" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15425</a></p>
<p>5、终于要出手解决监控的问题了，汇总监控，以前的监控受限于rs的个数</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15742" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15742</a></p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-14470" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-14470</a></p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15728" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15728</a></p>
<p>6、为set batch的一些代码传输了所有的错误堆栈信息</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15711" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15711</a></p>
<p>7、增加admin动作的一些权限控制</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15388" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15388</a></p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-15128" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-15128</a></p>
<p>8、表权限的控制</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-14809" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-14809</a></p>
<p>9、通过创建多备份，实现读写分离，加快读的速度，有点针对kudu</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-10070" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-10070</a></p>
<p>10、可以不停服务的更新配置</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-12147" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-12147</a></p>
<p>11、单列簇的flush</p>
<p> <a href="https://issues.apache.org/jira/browse/HBASE-10201" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-10201</a></p>
<p>12、单个列簇的时间范围scan</p>
<p><a href="https://issues.apache.org/jira/browse/HBASE-14355" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-14355</a></p>
<p>13、一个比较老的特性，就是表的实时增量备份，但是一直不稳定，不建议线上用</p>
<p><a href="https://hbase.apache.org/0.94/replication.html" target="_blank" rel="external">https://hbase.apache.org/0.94/replication.html</a></p>
<h1 id="一些其它的整理："><a href="#一些其它的整理：" class="headerlink" title="一些其它的整理："></a>一些其它的整理：</h1><p>HBase的一个检测表运行状态的工具 </p>
<p><a href="http://blog.csdn.net/yueyedeai/article/details/17646393" target="_blank" rel="external">http://blog.csdn.net/yueyedeai/article/details/17646393</a></p>
<p>一个不错的博客</p>
<p><a href="https://zh.hortonworks.com/blog/apache-hbase-region-splitting-and-merging/" target="_blank" rel="external">https://zh.hortonworks.com/blog/apache-hbase-region-splitting-and-merging/</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/12/27/java基础面试之volatile关键字/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/12/27/java基础面试之volatile关键字/" itemprop="url">java基础面试之volatile关键字</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-12-26T22:48:51-08:00">
                2015-12-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>作为一个java开发者，面试别人，被别人面试的过程中，经常会有一些常用的面试题，今天我们讲一讲java关键字volatile。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p> volatile可以保证被修饰变量的读可见性，不能保证被修饰变量的原子性，所以不是线程安全的。</p>
<p> 再白话一点，对于volatile修饰的变量，在多线程的场景下，不同线程在同一时刻读取到的变量值一定是一致的，但是在同一时刻修改该变量的时候不能保证结果的原子性。</p>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>现在的java内存模型中，线程在读取变量的值的时候，首先会通过该变量的引用找到堆上内存中变量的值，如果这个变量没有被申明为volatile，那么当前线程会把对内的变量的值拷贝到本地的内存(一般来说是各种寄存器)中。</p>
<p>上面描述的内存模型中，如果一个线程在修改完一个值的时候，另一个线程中使用的变量依旧是它写入到本地内存中的拷贝，最终导致读的不一致性。</p>
<p>volatile可以用来解决读不一致的问题，使用volatile修饰的变量在每次被线程访问时，都强迫从堆内存(或者静态常量区)中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到堆内存(或者静态常量区)中。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 </p>
<p>volatile为什么不可以保证被修饰变量的原子性呢，其实道理很简单，volatile只保证了读的过程中数据都从堆内存(或者静态常量区)中读，但是当并发同时读到该数据后，却不能保证写是原子的，所以不能保证被修饰变量的原子性，详细可见<strong>示例</strong>。</p>
<h2 id="延伸阅读"><a href="#延伸阅读" class="headerlink" title="延伸阅读"></a>延伸阅读</h2><h3 id="指令重排序的问题"><a href="#指令重排序的问题" class="headerlink" title="指令重排序的问题"></a>指令重排序的问题</h3><p>volatile关键字还有一个非常重要的作用，即局部阻止指令重排序。对于java内存重排序的问题，可以参考<a href="http://www.infoq.com/cn/articles/java-memory-model-2/" target="_blank" rel="external">http://www.infoq.com/cn/articles/java-memory-model-2/</a></p>
<p>对于单线程的程序，遵循as-if-serial的原则，不管怎么重排序，执行结果不会被改变。</p>
<p>但是在多线程的场景中，就会发生异常，如上文关于重排序的描述中的例子，那么怎么解决问题呢，可以使用volatile关键字。使用volatile关键字修饰的变量编译前后的顺序相对不变，怎么理解呢，简单来说如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writer</span><span class="params">()</span> </span>&#123;</div><div class="line">    a = <span class="number">1</span>;                   <span class="comment">//1</span></div><div class="line">    flag = <span class="keyword">true</span>;             <span class="comment">//2</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reader</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span> (flag) &#123;                <span class="comment">//3</span></div><div class="line">        <span class="keyword">int</span> i =  a * a;        <span class="comment">//4</span></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>按照上文中的例子，如果writer和reader是分别在不同的线程中，可能因为指令重排序的问题，导致在reader中的变量i一直是0或者一直是1，因为在writer方法中，a和flag变量的编译顺序是随机的，会根据不同的jdk版本或者编译器而导致顺序不同，但是如果把flag变量使用volatile修饰，那么就可以保证结果一致为1，因为能永远保证编译后a变量先于flag初始化(<strong>注意，这个规则在下面介绍</strong>)。</p>
<h3 id="内存屏障的问题"><a href="#内存屏障的问题" class="headerlink" title="内存屏障的问题"></a>内存屏障的问题</h3><p>重排序是有一些规则的，这些规则就涉及到了内存屏障的问题，首先来描述一下volatile对于指令重排序的规则：</p>
<p>1、当第一个操作为普通的读或写时，如果第二个操作为volatile写，则编译器不能重排序这两个操作(比如上面的例子)<br>2、当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前<br>3、当第一个操作是volatile写，第二个操作是volatile读时，不能重排序<br>4、当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序(也符合上面的例子)</p>
<p>那么编译器是如何保证如上的规则呢，实际依靠的是内存屏障的方法：</p>
<p>在介绍规则之前，先请大家移步<a href="http://gee.cs.oswego.edu/dl/jmm/cookbook.html" target="_blank" rel="external">http://gee.cs.oswego.edu/dl/jmm/cookbook.html</a> 查看相关的屏障类型</p>
<p>1、在每个volatile写操作的前面插入一个StoreStore屏障<br>2、在每个volatile写操作的后面插入一个SotreLoad屏障<br>3、在每个volatile读操作的后面插入一个LoadLoad屏障<br>4、在每个volatile读操作的后面插入一个LoadStore屏障</p>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><p>执行环境：jdk1.8</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> kw;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"> * Created by aiping.lap on 15/12/26.</div><div class="line"> *</div><div class="line"> * <span class="doctag">@author</span> aiping.lap</div><div class="line"> * <span class="doctag">@date</span> 2015/12/26</div><div class="line"> */</div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">VolatileTest</span> </span>&#123;</div><div class="line">    <span class="keyword">public</span> <span class="keyword">volatile</span> <span class="keyword">static</span> <span class="keyword">int</span> i = <span class="number">0</span>;</div><div class="line"></div><div class="line">  <span class="comment">//构造一个+1的方法</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span></span>&#123;</div><div class="line">        i ++;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            TimeUnit.MILLISECONDS.sleep(<span class="number">1L</span>);</div><div class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>;i ++) &#123;</div><div class="line">            <span class="keyword">new</span> Thread() &#123;</div><div class="line">                <span class="meta">@Override</span></div><div class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</div><div class="line">                    add();</div><div class="line">                &#125;</div><div class="line">            &#125;.start();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        System.out.println(i);</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">999</div><div class="line"></div><div class="line">Process finished with exit code 0</div></pre></td></tr></table></figure>
<p>以上程序多运行几次，会偶尔有出现不是1000的情况。</p>
<h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>先来一个简单的总结：</p>
<p>1、volatile起初是在synchronized性能低下的时候提出的。如今synchronized的效率已经大幅提升，所以volatile存在的意义不大。</p>
<p>2、如今非volatile的共享变量，在访问不是超级频繁的情况下，已经和volatile修饰的变量有同样的效果了，现在大部分的变量在本地修改完成后，也会立马同步到堆(或者静态的变量区)，所以如果不是大并发量，根本不会出现问题了</p>
<p>3、volatile不能保证原子性，这点一点要搞清楚，用它修饰的变量不能保证线程安全</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/27/HBase0-98以后的版本直接读取HFile文件/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/10/27/HBase0-98以后的版本直接读取HFile文件/" itemprop="url">HBase0.98以后的版本直接读取HFile文件</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-26T21:58:32-08:00">
                2015-10-26
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在一些特殊的场景下，我们可能需要直接去读取HBase的HFile文件来替代通过HBase Coonection的方式读取Hbase的表信息。</p>
<h1 id="主要的好处是"><a href="#主要的好处是" class="headerlink" title="主要的好处是"></a>主要的好处是</h1><p>1、可以减少对Server的压力</p>
<p>2、在一些特殊的场景下，如果服务出现问题，需要恢复数据的时候，只能通过这种方式</p>
<p>3、对于一些离线的读操作(保证这个时间段没有大量的写操作,且能容忍 一定的错误比率)，完全可以通过直接读HFIle来替代原来的方式</p>
<p>总的来说，这种方式比较适合在写入量极少(最好没有写入)的需求下，需要扫描全表，或者一定范围的需求</p>
<h1 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h1><p>1、为了降低读取成本，一般来说，在读取之前可以先进行一个compact，或者进行一个major compact</p>
<p>2、读取的代码如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//获取到HBase的根目录，这个不需要用户自己制定，只需要使用默认的配置生成即可</span></div><div class="line"></div><div class="line">Path rootDir = FSUtils.getRootDir(conf);</div><div class="line">LOG.info(<span class="string">"Get Root HBase dir "</span> + rootDir);</div><div class="line"></div><div class="line"><span class="comment">//制定要读取的表，然后获取表在hdfs上的绝对路径</span></div><div class="line">Path tablePath = FSUtils.getTableDir(rootDir, TableName.valueOf(tableName));</div><div class="line">LOG.info(<span class="string">"Get Table dir "</span> + tablePath);</div><div class="line">FileSystem fs = tablePath.getFileSystem(conf);</div><div class="line"></div><div class="line"><span class="comment">//获取当前表的所有region list，如果有特定的范围需求，可以通过一个filter，过滤需要的region</span></div><div class="line">List allRegionPath = FSUtils.getRegionDirs(fs, tablePath);</div><div class="line">List storeFilePaths = <span class="keyword">new</span> ArrayList();</div><div class="line"></div><div class="line"><span class="comment">//循环所有的region路径</span></div><div class="line"><span class="keyword">for</span> (Path regionPath: allRegionPath)&#123;</div><div class="line">	LOG.info(<span class="string">"Get region path "</span> + regionPath);</div><div class="line">	</div><div class="line">	<span class="comment">//指定过滤特殊的region过滤</span></div><div class="line">	PathFilter dirFilter = <span class="keyword">new</span> FSUtils.DirFilter(fs);</div><div class="line">    <span class="comment">//获取指定的region下所有的store file文件，如果进行major compact，这个文件个数为1  </span></div><div class="line">  	FileStatus[] familyStatus = fs.listStatus(regionPath,dirFilter);</div><div class="line">    <span class="comment">//循环所有的sotrefile</span></div><div class="line">	<span class="keyword">for</span> (FileStatus fileStatus: familyStatus)&#123;</div><div class="line">    	FileStatus[] storeFiles = fs.listStatus(fileStatus.getPath());</div><div class="line">        <span class="comment">//记录所有已经读取的rowkey</span></div><div class="line">        List rowKeyList = <span class="keyword">new</span> ArrayList(); </div><div class="line">        <span class="keyword">if</span> (HConstants.RECOVERED_EDITS_DIR.equals(fileStatus.getPath().getName()))&#123;</div><div class="line">             <span class="comment">// if it is wal edits file,skip!</span></div><div class="line">			<span class="keyword">continue</span>;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">        <span class="comment">//遍历sotrefile</span></div><div class="line">		<span class="keyword">for</span> (FileStatus storeFile: storeFiles)&#123;</div><div class="line">             <span class="comment">//默认的情况，在storefile的同一层有一些元数据的文件，这些文件不包含有要读取的数据，所以直接跳过，这个方法比较暴力，但是目前没有看到HBase提供了判断一个路径是否是storefile的方法，只能这么干</span></div><div class="line">			<span class="keyword">if</span> (!storeFile.isDirectory())&#123;</div><div class="line">				LOG.info(<span class="string">"get store file path:"</span>+storeFile.getPath().getName());</div><div class="line">				storeFilePaths.add(storeFile.getPath());</div><div class="line">                 <span class="comment">//构造HFile.Reader对象，读取storefile路径下的所有文件</span></div><div class="line">				HFile.Reader hfileReader = HFile.createReader(fs, storeFile.getPath(), <span class="keyword">new</span> CacheConfig(conf), conf);</div><div class="line">				<span class="comment">// Map fileInfo = hfileReader.loadFileInfo();</span></div><div class="line">                 </div><div class="line">                  <span class="comment">//获取scanner对象，开始读取</span></div><div class="line">				 HFileScanner hFileScanner = hfileReader.getScanner(<span class="keyword">false</span>, <span class="keyword">false</span>, <span class="keyword">false</span>);</div><div class="line">                  hFileScanner.seekTo();</div><div class="line"></div><div class="line">				<span class="keyword">do</span>&#123;</div><div class="line">                      <span class="comment">//读取文件中的一行记录</span></div><div class="line">					Cell cell = hFileScanner.getKeyValue();</div><div class="line">						</div><div class="line">                      <span class="comment">//获取当前行的所有信息，打印</span></div><div class="line">					String rowKey = <span class="keyword">new</span> String(CellUtil.cloneRow(cell));</div><div class="line">					<span class="keyword">if</span> (rowKeyList.contains(rowKey))&#123;</div><div class="line">						<span class="keyword">continue</span>;</div><div class="line">					&#125;</div><div class="line">					rowKeyList.add(rowKey);</div><div class="line">					LOG.info(<span class="string">"count "</span> + rowKeyList.size() + <span class="string">"RowName:"</span> + rowKey+ <span class="string">" "</span>);</div><div class="line">					LOG.debug(<span class="string">"Timetamp:"</span> + cell.getTimestamp() + <span class="string">" "</span>);</div><div class="line">					LOG.debug(<span class="string">"column Family:"</span> + <span class="keyword">new</span> String(CellUtil.cloneFamily(cell)) + <span class="string">" "</span>);</div><div class="line">					LOG.debug(<span class="string">"row Name:"</span> + <span class="keyword">new</span> String(CellUtil.cloneQualifier(cell)) + <span class="string">" "</span>);</div><div class="line">					LOG.debug(<span class="string">"value:"</span> + <span class="keyword">new</span> String(CellUtil.cloneValue(cell)) + <span class="string">" "</span>);</div><div class="line">				&#125; <span class="keyword">while</span>(hFileScanner.next());</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		LOG.info(<span class="string">"Store File "</span>+fileStatus.getPath()+<span class="string">" containes row "</span>+rowKeyList.size()+<span class="string">" lines!"</span>);</div><div class="line">	&#125;</div><div class="line">  &#125;</div><div class="line">&#125; <span class="keyword">catch</span> (Exception e)&#123;</div><div class="line">	e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/24/HBase-Region的状态迁移流程/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/10/24/HBase-Region的状态迁移流程/" itemprop="url">HBase Region的状态迁移流程</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-23T21:33:34-08:00">
                2015-10-23
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><img src="http://hbase.apache.org/images/region_states.png" alt="HBase Region状态迁移"></p>
<p>1、master控制把一个region从offline的状态迁移到opening 的状态，并且把该region分配到一个regionServer上。在到达rpc的重试最大次数(11次)之前，master会一直尝试发送打开region的请求。等到regionserver接收到request之后，就会开始打开region</p>
<p>2、如果master超过请求重试次数，master会停止启动region，然后把该region迁移到closing的状态，然后停止该region(注意，这里即使某个regnionserver已经开始打开该region，也会强制再停止的)。</p>
<p>3、等到regionserver打开region，它会一直notify master，直到master把该region的状态更改为open并且notifies所有的regionserver,到此为止，改region正式open</p>
<p>4、如果regionserver无法打开region，它会notify master，master会把region迁移到closed的状态，然后在其它的regionserver上重试打开</p>
<p>5、如果region无法打开，master会它迁移到failed_open的状态，直到hbase shell发出重新assign的命令，或者在该服务重启之前，对这个region将不再会有任何操作</p>
<p>6、master会把region从open到close的状态.regionserver会一直保持region直到收到close的状态</p>
<p>7、如果regionserver停止服务了，或者有NotServingRegionException异常的时候，master会负责把region迁移到offline的状态，然后把该region迁移到其它的reginserver</p>
<p>8、如果regionserver正常服务，但是在master重试多次后仍然不可达，master会把该region迁移到filed_close的状态，直到hbase shell发出重新assign的命令，或者在该服务重启之前，对这个region将不再会有任何操作</p>
<p>9、当regionserver得到关闭region的请求时候，它会关闭region，并且通知master，后者会把该region标记为closed的状态，并且会移动到其它的regionserver</p>
<p>10、在移动到其它的regionserver之前，master会先把一个closed的region标记为offline的状态</p>
<p>11、当一个regionserver准备split一个region，它会通知master。master会把将要切分的reigon从open状态移动到splitting状态，然后把切分出来的两个region初始化成spliting_new的状态</p>
<p>12、通知了master以后，regionserver开始切分region.如果返回超时，regionserver会再次通知master来更新hbase:meta表。在master确定split结束之前，master不会更新region的状态。如果split切分成功后，正在被切分的region会从splitting状态切换到split状态，然后被切分的两个新region会从splitting_new切换到open状态</p>
<p>13、如果切分失败，被切分的region从splitting状态切换回滚到open状态，然后两个新切出来的region被从splitting_new切换到offline的状态</p>
<p>14、如果regionserver要合并两个region，会先通知master。master会把要合并的两个region从open切换到merging的状态，然后增加一个新的region到regionserver，这个新的region是merging_new的状态</p>
<p>15、通知完master之后，regionserver开始合并region，一旦超时，regionserver会再次通知master来更新meta表。如果合并成功，两个正在合并的region会从merging迁移到merged状态，而新的region会从merging_new到open的状态</p>
<p>16、如果合并失败，两个需要合并的region会从merging迁移到open的状态，然后准备要合并到的目的region会从merging_new到offline的状态</p>
<p>17、对于一个region处于failed_open或者failed_close状态，master会尝试关闭这些节点.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/19/如何自定义一个HBase命令行的命令/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/10/19/如何自定义一个HBase命令行的命令/" itemprop="url">如何自定义一个HBase命令行的命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-18T21:06:06-08:00">
                2015-10-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在一些场景下，我们会大量频繁的执行一些HBase的代码，如果每次都通过jar命令的方式，会很麻烦，需要指定很多的系统库的路径，比如在前文中我们开发了一个单标balance的工具，想要把这个命令方便执行，那么最好的方法是把这个工具加入到命令行中，让这件事情变得傻瓜化。</p>
<h1 id="开发目的"><a href="#开发目的" class="headerlink" title="开发目的"></a>开发目的</h1><p>完成对单表的迅速balance小工具的命令行开发</p>
<h1 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h1><h2 id="1、自定义相应的命令行接口"><a href="#1、自定义相应的命令行接口" class="headerlink" title="1、自定义相应的命令行接口"></a>1、自定义相应的命令行接口</h2><figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">module</span> <span class="title">Shell</span></span></div><div class="line">  <span class="class"><span class="keyword">module</span> <span class="title">Commands</span></span></div><div class="line">    <span class="class"><span class="keyword">class</span> <span class="title">STableBalancer</span> &lt; Command</span></div><div class="line">      <span class="function"><span class="keyword">def</span> <span class="title">help</span></span></div><div class="line">        <span class="keyword">return</span> <span class="string">&lt;&lt;-EOF</span></div><div class="line">BaiFenDian table balancer. Returns true if balancer ran and was able to</div><div class="line">tell the region servers to unassign all the regions to balance  (the re-assignment itself is async). </div><div class="line">Otherwise false (Will not run if regions in transition). </div><div class="line">Author: aiping.liang</div><div class="line">Describe the named table. For example:</div><div class="line">    hbase&gt; bfd_table_balance 't1'</div><div class="line">EOF</div><div class="line">      <span class="keyword">end</span> </div><div class="line">      <span class="function"><span class="keyword">def</span> <span class="title">command</span><span class="params">(table_name)</span></span></div><div class="line">        format_simple_command <span class="keyword">do</span></div><div class="line">          formatter.row([admin.tableBalancer(table_name.to_java_bytes)? <span class="string">"true"</span>: <span class="string">"false"</span>]) </div><div class="line">        <span class="keyword">end</span> </div><div class="line">      <span class="keyword">end</span> </div><div class="line">    <span class="keyword">end</span> </div><div class="line">  <span class="keyword">end</span> </div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>这是一个简单的ruby脚本，稍微解释下，formatter.header、formatter.row、formatter.footer都是自定义的一些输出到命令行的一些命令，这里Class的方法一定要注意格式，因为Class的名字代表着命令行的名称</p>
<h2 id="2、定义自己操作对应的方法"><a href="#2、定义自己操作对应的方法" class="headerlink" title="2、定义自己操作对应的方法"></a>2、定义自己操作对应的方法</h2><p>增加改命令对应的实际的操作到HBase的admin命令行中</p>
<p>修改hbase-shell/src/main/ruby/hbase/admin.rb，如下</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#----------------------------------------------------------------------------------------------</span></div><div class="line"><span class="comment"># Requests a table balance</span></div><div class="line"><span class="comment"># Returns true if balancer ran</span></div><div class="line"><span class="comment"># Add by aiping.liang                                                                                                             </span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">tableBalancer</span><span class="params">(table_or_region_name)</span></span></div><div class="line">   @admin.tableBalancer(table_or_region_name)</div><div class="line"><span class="keyword">end</span></div></pre></td></tr></table></figure>
<p>​    注意，这里的@admin就是HBaseAdmin的对象</p>
<h2 id="3、实现相应的接口"><a href="#3、实现相应的接口" class="headerlink" title="3、实现相应的接口"></a>3、实现相应的接口</h2><p>   修改hbase-client/src/main/java/org/apache/hadoop/hbase/client/Admin.java接口，增加相应的接口方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">tableBalancer</span><span class="params">(<span class="keyword">final</span> <span class="keyword">byte</span>[] tableName)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">tableBalancer</span><span class="params">(<span class="keyword">final</span> TableName tableName)</span> <span class="keyword">throws</span>  IOException</span>;</div></pre></td></tr></table></figure>
<h2 id="4、实现该接口"><a href="#4、实现该接口" class="headerlink" title="4、实现该接口"></a>4、实现该接口</h2><p>   客户端默认的接口只有一个HBaseAdmin.java，实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tableBalancer</span><span class="params">(<span class="keyword">final</span> <span class="keyword">byte</span>[] tableName)</span> <span class="keyword">throws</span> IOException</span>&#123; </div><div class="line">    <span class="keyword">return</span> tableBalancer(TableName.valueOf(tableName));</div><div class="line">  &#125;</div><div class="line">  </div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tableBalancer</span><span class="params">(<span class="keyword">final</span> TableName tableName)</span><span class="keyword">throws</span> TableNotFoundException,IOException</span>&#123;</div><div class="line">          <span class="keyword">if</span> (!tableExists(tableName))&#123;</div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> TableNotFoundException(tableName);</div><div class="line">    &#125;   </div><div class="line">       <span class="keyword">return</span> <span class="keyword">true</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>   这一步需要实现自己的具体方法，具体的table balance的算法见上一篇文章</p>
<h2 id="5、-在命令行增加相应的命令"><a href="#5、-在命令行增加相应的命令" class="headerlink" title="5、 在命令行增加相应的命令"></a>5、 在命令行增加相应的命令</h2><p>  修改hbase-shell/src/main/ruby/shell.rb文件</p>
<figure class="highlight ruby"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Shell.load_command_group(  <span class="string">'ddl'</span>,  <span class="symbol">:full_name</span> =&gt; <span class="string">'TABLES MANAGEMENT COMMANDS'</span>,  <span class="symbol">:commands</span> =&gt; <span class="string">%w[     alter    bfd_table_balancer</span></div></pre></td></tr></table></figure>
<p>​    这一步是在命令行能自动tap，且使用自定义命令 必要的</p>
<h2 id="6、部署"><a href="#6、部署" class="headerlink" title="6、部署"></a>6、部署</h2><p>​    部署分两部分：</p>
<p>​     a、把更改后的包编译</p>
<p>​     b、 把hbase-client下相应的jar包，以及hbase-shell下修改的rb文件放到HBASE_HOME相应的路径下</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/10/16/实现一个HBase单表balance的工具/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/10/16/实现一个HBase单表balance的工具/" itemprop="url">实现一个HBase单表balance的工具</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-10-15T22:41:06-08:00">
                2015-10-15
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="需求-问题"><a href="#需求-问题" class="headerlink" title="需求+问题"></a>需求+问题</h1><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>所有人都知道HBase中表的region的分布对于读写性能影响很大，如果所有的region集中到一台机器上，势必会导致读写都很慢，所以我们希望HBase的Region能够尽量均匀的分布在集群的所有机器上。</p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>HBase自己有Balance的机智，主要是靠HMaster通过定期的检查所有机器的region分布来调整单个节点上的region个数，尽量保证整个集群的reigon在每台机器上的数量是接近的。</p>
<p>但是在一些特殊的场景下，会导致所有的reigon，或者很大部分的region分不到一台机器上</p>
<p>1、通过自定的rowkey分割方法对表进行预分配</p>
<p>2、HBase加载过程中，如果某一个region出问题，导致加载异常</p>
<p>3、表的个数小于集群机器数量，会导致一些机器个数多余其它机器</p>
<h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><p>主要的思路是，通过HMaster的管理机制，通过读取表的region个数，以及按照机器轮训的方式来对特定表负载更多region的机器迁移出一些reigon到负载低的机器上。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//初始化系统配置，读取要balance的表</span></div><div class="line">Configuration conf = <span class="keyword">new</span> Configuration();</div><div class="line">String tableName = args[<span class="number">0</span>];</div><div class="line"></div><div class="line"><span class="keyword">try</span> &#123;</div><div class="line">    <span class="comment">//创建HBase的连接</span></div><div class="line">    <span class="comment">//98以后最新的连接池的方法</span></div><div class="line">    Connection conn = ConnectionFactory.createConnection(conf);</div><div class="line"></div><div class="line">    <span class="comment">//存放所有的均衡表所有的信息，结构为region所在的机器HostName, 需要迁移的serverName对象，可以迁移的region的列别哦</span></div><div class="line">    Map regionCountCalculator = <span class="keyword">new</span> HashMap&lt;&lt;Integer&gt;&gt;();</div><div class="line"></div><div class="line">    <span class="comment">//创建HMaster的Admin对象,然后获取服务信息</span></div><div class="line">    Admin admin = conn.getAdmin();</div><div class="line">    ClusterStatus clusterStatus = admin.getClusterStatus();</div><div class="line">    Collection servers = clusterStatus.getServers();</div><div class="line"></div><div class="line">    <span class="keyword">int</span> serverTotal = servers.size();</div><div class="line">    <span class="keyword">for</span> (ServerName server:servers)&#123;</div><div class="line">        LOG.info(<span class="string">"Get Servername:"</span>+ server.getHostname());</div><div class="line">        <span class="comment">//初始化所有的RS存储信息</span></div><div class="line">        regionCountCalculator.put(server.getHostname(),  <span class="keyword">new</span> Pair&lt;&gt;(server, <span class="keyword">new</span> HashSet()));</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">// calculator the regionserver -- servername -- regionInfo</span></div><div class="line"></div><div class="line">    RegionLocator regionLocator = conn.getRegionLocator(TableName.valueOf(tableName));</div><div class="line">    Pair regionPari = regionLocator.getStartEndKeys();</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; regionPari.getFirst().length;i++)&#123;</div><div class="line">        LOG.info(<span class="string">"Get Start Key"</span> + <span class="keyword">new</span> String(CellUtil.cloneRow(CellUtil.createCell(regionPari.getFirst()[i]))));</div><div class="line">        HRegionLocation regionLocat = regionLocator.getRegionLocation(regionPari.getFirst()[i], <span class="keyword">false</span>);</div><div class="line">        String regionHostName = regionLocat.getHostname();</div><div class="line">        <span class="comment">//初始化regionCountCalculator对象中的servername对象，并且把所有的该节点上的region初始化</span></div><div class="line">        regionCountCalculator.get(regionHostName).getSecond().add(regionLocat.getRegionInfo());</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">//按照机器数，获取平均每台机器上应该存储的region的数量</span></div><div class="line">    <span class="keyword">int</span> avgRegionNum = regionPari.getFirst().length/serverTotal;</div><div class="line">    <span class="comment">//初始化两个小map，类似，分别存放可以移入和移出的region信息</span></div><div class="line">    Map moveOutMap = <span class="keyword">new</span> HashMap();</div><div class="line">    Map moveInMap = <span class="keyword">new</span> HashMap();</div><div class="line"></div><div class="line">    <span class="comment">//第一遍轮训获取所有的可以移入和移除的region信息</span></div><div class="line">    <span class="keyword">for</span> (String hostKey: regionCountCalculator.keySet())&#123;</div><div class="line">        <span class="comment">//获取当前机器上已经分配的region的个数</span></div><div class="line">        <span class="keyword">int</span> regionCount = regionCountCalculator.get(hostKey).getSecond().size();</div><div class="line">        LOG.info(<span class="string">"Get region count:"</span>+regionCount+<span class="string">" and avgRegionNum:"</span>+avgRegionNum);</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (regionCount &lt; avgRegionNum)&#123;</div><div class="line">            <span class="comment">//如果小于平均值，则表明该server可以写入region</span></div><div class="line">            moveInMap.put(regionCountCalculator.get(hostKey).getFirst(), avgRegionNum-regionCount+<span class="number">1</span>);</div><div class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (regionCount &gt; avgRegionNum+<span class="number">1</span>)&#123;</div><div class="line">            <span class="comment">//相反，如果大于平均值，则表明该server可移出region</span></div><div class="line">            moveOutMap.put(regionCountCalculator.get(hostKey).getFirst(), regionCount-avgRegionNum);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">    LOG.info(<span class="string">"Get in length:"</span>+moveInMap.size()+<span class="string">" and out length:"</span>+moveOutMap.size());</div><div class="line">    <span class="comment">//第二遍轮训开始迁移所有的可以移除和移入的region</span></div><div class="line">    <span class="comment">//轮寻所有需要移除的队列</span></div><div class="line">    <span class="keyword">for</span> (ServerName outHost: moveOutMap.keySet())&#123;</div><div class="line">        <span class="keyword">boolean</span> needMoveOut = <span class="keyword">true</span>;</div><div class="line">        <span class="comment">//记录已经移出的个数，如果超过可移除的最大值，则停止移除</span></div><div class="line">        <span class="keyword">int</span> moveCount = moveOutMap.get(outHost);</div><div class="line"></div><div class="line">        <span class="keyword">for</span> (HRegionInfo moveOutRegionInfo:regionCountCalculator.get(outHost.getHostname()).getSecond())&#123;</div><div class="line">            <span class="keyword">if</span> (needMoveOut)&#123;</div><div class="line">                ServerName inHost = <span class="keyword">null</span>;</div><div class="line">                <span class="keyword">int</span> inCount = <span class="number">0</span>;</div><div class="line">                <span class="comment">//轮寻所有的可以移入的队列，获取可以移入的机器</span></div><div class="line">                <span class="keyword">for</span> (ServerName moveInHost: moveInMap.keySet())&#123;</div><div class="line">                    inCount = moveInMap.get(moveInHost);</div><div class="line">                    LOG.info(<span class="string">"Host in :"</span>+moveInHost+<span class="string">" can be in :"</span>+inCount);</div><div class="line">                    <span class="keyword">if</span> (inCount &gt; <span class="number">0</span> )&#123;</div><div class="line">                        inHost = moveInHost;</div><div class="line">                    &#125;</div><div class="line">                &#125;</div><div class="line">                LOG.info(<span class="string">"Move Region "</span>+moveOutRegionInfo.getRegionNameAsString()+<span class="string">" from "</span>+outHost.getHostname() + <span class="string">" to "</span>+inHost.getHostname());</div><div class="line">                <span class="keyword">int</span> outCount = <span class="number">0</span>;</div><div class="line">                <span class="keyword">if</span> (moveOutRegionInfo != <span class="keyword">null</span>)&#123;</div><div class="line">                    <span class="comment">//调用服务管理接口，把region移动到相应的机器</span></div><div class="line">                    admin.move(moveOutRegionInfo.getEncodedNameAsBytes(), Bytes.toBytes(inHost.toString()));</div><div class="line">                    LOG.info(<span class="string">"Move from: "</span>+moveOutRegionInfo.getRegionNameAsString()+<span class="string">" to:"</span>+inHost.toString());</div><div class="line"></div><div class="line">                &#125;</div><div class="line">                moveInMap.remove(inHost);</div><div class="line">                <span class="keyword">if</span> (--inCount &gt; <span class="number">0</span>)&#123;</div><div class="line">                    <span class="comment">//如果可移入的机器已经移入最大值，则从map中移除</span></div><div class="line">                    moveInMap.put(inHost,inCount);</div><div class="line">                &#125;</div><div class="line"></div><div class="line">                <span class="keyword">if</span> (--moveCount == <span class="number">0</span>)&#123;</div><div class="line">                    needMoveOut = <span class="keyword">false</span>;</div><div class="line">                    <span class="comment">//如果需要移出的机器已经把所有的region都移出，则从map中删除</span></div><div class="line">                    outCount++;</div><div class="line">                &#125;</div><div class="line">            &#125; <span class="keyword">else</span> &#123;</div><div class="line">                <span class="keyword">break</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        LOG.info(<span class="string">"Get out host length:"</span>+moveOutMap.size());</div><div class="line">    &#125;</div><div class="line">&#125;<span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">    <span class="comment">//handle exception</span></div><div class="line">    e.printStackTrace();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>通过以上一个小小的脚本，解决了我们的问题。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2015/04/07/记录一次HBase的问题排查/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="aiping.lap">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Aiping.LAP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2015/04/07/记录一次HBase的问题排查/" itemprop="url">记录一次HBase的问题排查</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2015-04-06T19:22:14-08:00">
                2015-04-06
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="问题现象"><a href="#问题现象" class="headerlink" title="问题现象"></a>问题现象</h1><p>所有的region被卡死，无法打开，访问缓慢</p>
<h1 id="问题跟踪"><a href="#问题跟踪" class="headerlink" title="问题跟踪"></a>问题跟踪</h1><p>老实说，这个现象很常见，有时候是因为压力太大，有时候因为别的原因，所以我这里的跟进方法是一般的一个方法，但是不能解决所有问题，具体问题需要具体分析。</p>
<h1 id="1、找到有问题的region"><a href="#1、找到有问题的region" class="headerlink" title="1、找到有问题的region"></a>1、找到有问题的region</h1><p>这个方法比较多，一般来说可以根据请求慢的key，以及通过管理页面，定位到确定的出问题的Region，一个形如0313e59d82326803c21470f5c25fef79的串</p>
<h2 id="2、查找出问题region所在的物理机"><a href="#2、查找出问题region所在的物理机" class="headerlink" title="2、查找出问题region所在的物理机"></a>2、查找出问题region所在的物理机</h2><p>从管理页面上看到的region分布不一定是正确的分布，因为中间可能发生过迁移，所以最稳妥的方法是去Master上搜索所有和这个region相关的日志，查找出问题时间段这个region应该所处的节点，例如发现如下日志</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">2015</span>-<span class="number">04</span>-<span class="number">05</span> <span class="number">14</span>:<span class="number">08</span>:<span class="number">49</span>,<span class="number">257</span> INFO org.apache.hadoop.hbase.master.AssignmentManager: Server bjlg-<span class="number">48</span>p28-hadoop18.bfdabc.com,<span class="number">60020</span>,<span class="number">1420985184893</span> returned java.net.SocketTimeoutException: Call to [bjlg-<span class="number">48</span>p28-hadoop18.bfdabc.com/<span class="number">192.168</span>.48.28:<span class="number">60020</span>](http:<span class="comment">//bjlg-48p28-hadoop18.bfdabc.com/192.168.48.28:60020) failed on socket timeout exception: java.net.SocketTimeoutException: 20000 millis timeout while waiting for channel to be ready for connect. ch : java.nio.channels.SocketChannel[connection-pending remote=[bjlg-48p28-hadoop18.bfdabc.com/192.168.48.28:60020](http://bjlg-48p28-hadoop18.bfdabc.com/192.168.48.28:60020)] for 0313e59d82326803c21470f5c25fef79</span></div></pre></td></tr></table></figure>
<h2 id="3、到相关的节点上进一步排查"><a href="#3、到相关的节点上进一步排查" class="headerlink" title="3、到相关的节点上进一步排查"></a>3、到相关的节点上进一步排查</h2><p>一般来说，先从机器的load，或者磁盘使用率、cpu使用率、内存状况等开始入手排查，这些基本的我都跳过了，直接说一个我们的问题：查看regionserver的进程，发现了一个死锁</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># Found one Java-level deadlock:</div><div class="line"></div><div class="line">"IPC Server handler 39 on 60020":</div><div class="line">waiting to lock monitor 0x00002aaac9c5b838 (object 0x000000058cacc9b8, a java.lang.Object),</div><div class="line">which is held by "regionserver60020.logRoller"</div><div class="line">"regionserver60020.logRoller":</div><div class="line">waiting to lock monitor 0x00002aaac981f4d0 (object 0x000000058cacc9d0, a java.lang.Object),</div><div class="line">which is held by "IPC Server handler 37 on 60020"</div><div class="line">"IPC Server handler 37 on 60020":</div><div class="line">waiting to lock monitor 0x00002aaac9c5b838 (object 0x000000058cacc9b8, a java.lang.Object),</div><div class="line">which is held by "regionserver60020.logRoller"</div></pre></td></tr></table></figure>
<h2 id="4、跟踪死锁的进程："><a href="#4、跟踪死锁的进程：" class="headerlink" title="4、跟踪死锁的进程："></a>4、跟踪死锁的进程：</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="string">"IPC Server handler 39 on 60020"</span>:</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.append(HLog.[java:<span class="number">1122</span>](http:<span class="comment">//java:1122/))</span></div><div class="line">\- waiting to lock &lt;<span class="number">0x000000058cacc9b8</span>&gt; (a java.lang.Object)</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.appendNoSync(HLog.[java:<span class="number">1168</span>](http:<span class="comment">//java:1168/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.[java:<span class="number">2225</span>](http:<span class="comment">//java:2225/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.[java:<span class="number">1973</span>](http:<span class="comment">//java:1973/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.[java:<span class="number">3492</span>](http:<span class="comment">//java:3492/))</span></div><div class="line">at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)</div><div class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">25</span>)</div><div class="line">at java.lang.reflect.Method.invoke(Method.[java:<span class="number">597</span>](http:<span class="comment">//java:597/))</span></div><div class="line">at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.[java:<span class="number">364</span>](http:<span class="comment">//java:364/))</span></div><div class="line">at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.[java:<span class="number">1426</span>](http:<span class="comment">//java:1426/))</span></div><div class="line"><span class="string">"regionserver60020.logRoller"</span>:</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.syncer(HLog.[java:<span class="number">1302</span>](http:<span class="comment">//java:1302/))</span></div><div class="line">\- waiting to lock &lt;<span class="number">0x000000058cacc9d0</span>&gt; (a java.lang.Object)</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.syncer(HLog.[java:<span class="number">1280</span>](http:<span class="comment">//java:1280/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.[java:<span class="number">1433</span>](http:<span class="comment">//java:1433/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.cleanupCurrentWriter(HLog.[java:<span class="number">866</span>](http:<span class="comment">//java:866/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.rollWriter(HLog.[java:<span class="number">640</span>](http:<span class="comment">//java:640/))</span></div><div class="line">\- locked &lt;<span class="number">0x000000058cacc9b8</span>&gt; (a java.lang.Object)</div><div class="line">at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:<span class="number">94</span>)</div><div class="line">at java.lang.Thread.run(Thread.[java:<span class="number">662</span>](http:<span class="comment">//java:662/))</span></div><div class="line"><span class="string">"IPC Server handler 37 on 60020"</span>:</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.syncer(HLog.[java:<span class="number">1311</span>](http:<span class="comment">//java:1311/))</span></div><div class="line">\- waiting to lock &lt;<span class="number">0x000000058cacc9b8</span>&gt; (a java.lang.Object)</div><div class="line">\- locked &lt;<span class="number">0x000000058cacc9d0</span>&gt; (a java.lang.Object)</div><div class="line">at org.apache.hadoop.hbase.regionserver.wal.HLog.sync(HLog.[java:<span class="number">1437</span>](http:<span class="comment">//java:1437/))</span></div><div class="line"></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegion.syncOrDefer(HRegion.[java:<span class="number">5205</span>](http:<span class="comment">//java:5205/))</span></div><div class="line"></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegion.doMiniBatchMutation(HRegion.[java:<span class="number">2245</span>](http:<span class="comment">//java:2245/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegion.batchMutate(HRegion.[java:<span class="number">1973</span>](http:<span class="comment">//java:1973/))</span></div><div class="line">at org.apache.hadoop.hbase.regionserver.HRegionServer.multi(HRegionServer.[java:<span class="number">3492</span>](http:<span class="comment">//java:3492/))</span></div><div class="line">at sun.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)</div><div class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">25</span>)</div><div class="line">at java.lang.reflect.Method.invoke(Method.[java:<span class="number">597</span>](http:<span class="comment">//java:597/))</span></div><div class="line">at org.apache.hadoop.hbase.ipc.WritableRpcEngine$Server.call(WritableRpcEngine.[java:<span class="number">364</span>](http:<span class="comment">//java:364/))</span></div><div class="line">at org.apache.hadoop.hbase.ipc.HBaseServer$Handler.run(HBaseServer.[java:<span class="number">1426</span>](http:<span class="comment">//java:1426/))</span></div></pre></td></tr></table></figure>
<h2 id="5、分析"><a href="#5、分析" class="headerlink" title="5、分析"></a>5、分析</h2><p>最后确定这是logRoller和HLog.syncer两个线程发生了死锁。</p>
<p>在HBase，采用WAL(Write Ahead Log)的方式来保证数据不丢失。一个Region Server对应一个HLog，任何数据都是先写HLog，然后才真正的写MemStore。HLog文件有个轮转的过程，当达到默认大小（一般是block size * 0.95）就会写一个新的HLog文件，logRoller线程就是做这个事情的。而buffer中的数据每隔一秒钟会写一次HLog文件，这个是HLog.syncer线程负责的。logRoller和HLog.syncer进程不能同时进行，不然会导致数据问题，于是就需要通过锁来进行互斥了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">append</span><span class="params">(HRegionInfo info, <span class="keyword">byte</span> [] tableName, WALEdit edits, UUID clusterId,</span></span></div><div class="line"></div><div class="line"><span class="keyword">final</span> <span class="keyword">long</span> now, HTableDescriptor htd, <span class="keyword">boolean</span> doSync)</div><div class="line"></div><div class="line"><span class="keyword">throws</span> IOException &#123;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (edits.isEmpty())</div><div class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.unflushedEntries.get();</div><div class="line">    ;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.closed) &#123;</div><div class="line"></div><div class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Cannot append; log is closed"</span>);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">long</span> txid = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>.updateLock) &#123; <span class="comment">//在追加Hlog文件的时候，需要获取到文件的锁</span></div><div class="line"></div><div class="line">        <span class="keyword">long</span> seqNum = obtainSeqNum();</div><div class="line"></div><div class="line">        <span class="comment">// The 'lastSeqWritten' map holds the sequence number of the oldest</span></div><div class="line"></div><div class="line">        <span class="comment">// write for each region (i.e. the first edit added to the particular</span></div><div class="line"></div><div class="line">        <span class="comment">// memstore). . When the cache is flushed, the entry for the</span></div><div class="line"></div><div class="line">        <span class="comment">// region being flushed is removed if the sequence number of the flush</span></div><div class="line"></div><div class="line">        <span class="comment">// is greater than or equal to the value in lastSeqWritten.</span></div><div class="line"></div><div class="line">        <span class="comment">// Use encoded name.  Its shorter, guaranteed unique and a subset of</span></div><div class="line"></div><div class="line">        <span class="comment">// actual  name.</span></div><div class="line"></div><div class="line">        <span class="keyword">byte</span>[] encodedRegionName = info.getEncodedNameAsBytes();</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.lastSeqWritten.putIfAbsent(encodedRegionName, seqNum);</div><div class="line"></div><div class="line">        HLogKey logKey = makeKey(encodedRegionName, tableName, seqNum, now, clusterId);</div><div class="line"></div><div class="line">        doWrite(info, logKey, edits, htd);</div><div class="line"></div><div class="line">        <span class="keyword">this</span>.numEntries.incrementAndGet();</div><div class="line"></div><div class="line">        txid = <span class="keyword">this</span>.unflushedEntries.incrementAndGet();</div><div class="line"></div><div class="line">        <span class="keyword">if</span> (htd.isDeferredLogFlush()) &#123;</div><div class="line"></div><div class="line">            lastDeferredTxid = txid;</div><div class="line"></div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">        <span class="keyword">long</span> doneUpto;</div><div class="line"></div><div class="line">        <span class="keyword">long</span> now = System.currentTimeMillis();</div><div class="line"></div><div class="line">        <span class="comment">// First flush all the pending writes to HDFS. Then</span></div><div class="line"></div><div class="line">        <span class="comment">// issue the sync to HDFS. If sync is successful, then update</span></div><div class="line"></div><div class="line">        <span class="comment">// syncedTillHere to indicate that transactions till this</span></div><div class="line"></div><div class="line">        <span class="comment">// number has been successfully synced.</span></div><div class="line"></div><div class="line">        <span class="keyword">synchronized</span> (flushLock) &#123;</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (txid &lt;= <span class="keyword">this</span>.syncedTillHere) &#123;</div><div class="line"></div><div class="line">                <span class="keyword">return</span>;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            doneUpto = <span class="keyword">this</span>.unflushedEntries.get();</div><div class="line"></div><div class="line">            List pending = logSyncerThread.getPendingWrites();</div><div class="line"></div><div class="line">            <span class="keyword">try</span> &#123;</div><div class="line"></div><div class="line">                logSyncerThread.hlogFlush(tempWriter, pending);</div><div class="line"></div><div class="line">            &#125; <span class="keyword">catch</span> (IOException io) &#123;</div><div class="line"></div><div class="line">                <span class="keyword">synchronized</span> (<span class="keyword">this</span>.updateLock) &#123; <span class="comment">//当hlogFlush发生exception的时候发生了死锁</span></div><div class="line"></div><div class="line">                    <span class="comment">// HBASE-4387, HBASE-5623, retry with updateLock held</span></div><div class="line"></div><div class="line">                    tempWriter = <span class="keyword">this</span>.writer;</div><div class="line"></div><div class="line">                    logSyncerThread.hlogFlush(tempWriter, pending);</div><div class="line"></div><div class="line">                &#125;</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div></pre></td></tr></table></figure>
<p>查看了下代码，是在logSyncerThread.hlogFlush往HDFS写文件发生IO Exception时会触发死锁。<a href="http://www.rigongyizu.com/tag/hbase/" target="_blank" rel="external">hbase</a> 0.94.X版本的一个bug，在社区已经修复了：<a href="https://issues.apache.org/jira/browse/HBASE-7728" target="_blank" rel="external">https://issues.apache.org/jira/browse/HBASE-7728</a>。</p>
<h2 id="6、修复"><a href="#6、修复" class="headerlink" title="6、修复"></a>6、修复</h2><p>​    临时的修复方案是sync所有的memstore后、重启regionserver</p>
<p>​    长久的修复方案就是老老实实打patch修复</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">aiping.lap</p>
              <p class="site-description motion-element" itemprop="description">aiping.liang s home</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">43</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">8</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">aiping.lap</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
